#!/bin/bash

source "${CYCLECLOUD_PROJECT_PATH}/default/files/default.sh" || exit 1
source "${CYCLECLOUD_PROJECT_PATH}/default/files/utils.sh" || exit 1
source "${CYCLECLOUD_PROJECT_PATH}/default/files/hwlocs-install.sh" || exit 1

PACKAGE_NAME=$(jetpack config pbspro.package "") || fail
EXECUTE_HOSTNAME=$(jetpack config hostname) || fail
SERVER_HOSTNAME=$(jetpack config pbspro.scheduler "") || fail
CLUSTER_NAME=$(jetpack config cyclecloud.cluster.name) || fail

# Forces execute node's hostname to be updated (scalelib is blocked until the hostname is correct)
$(jetpack config cyclecloud.home)/system/embedded/bin/python -c "import jetpack.converge as jc; jc._send_installation_status('warning')"

if [[ -z "$PACKAGE_NAME" ]]; then
    if [[ "${PBSPRO_VERSION%%.*}" -lt 20 ]]; then
        PACKAGE_NAME="pbspro-execution-${PBSPRO_VERSION}.x86_64.rpm"
    else
        PACKAGE_NAME="openpbs-execution-${PBSPRO_VERSION}.x86_64.rpm"
    fi
fi

jetpack download --project pbspro "$PACKAGE_NAME" "/tmp" || fail
yum install -y "/tmp/$PACKAGE_NAME" || fail # TODO: this is slow, won't work on all linux distros, and will not be final--Emily and Doug's install-package will be used instead

if [[ -z "$SERVER_HOSTNAME" ]]; then
    MAX_RETRIES=10
    RETRY_DELAY=15
    ATTEMPT=1

    # Read server hostname from azpbs.env config file generated by server node
    if [[ ! -e "/sched/${CLUSTER_NAME}/azpbs.env" ]]; then
        while [[ $ATTEMPT -lt $MAX_RETRIES ]]; do
            sleep $RETRY_DELAY
            ((ATTEMPT+=1))
            
            if [[ -e "/sched/${CLUSTER_NAME}/azpbs.env" ]]; then
                break;
            fi
        done

        if [[ $ATTEMPT == $MAX_RETRIES ]]; then
            echo "Failed to read /sched/${CLUSTER_NAME}/azpbs.env after $MAX_RETRIES attempts. Exiting." 1>&2
            exit 1
        fi
    fi
    source "/sched/${CLUSTER_NAME}/azpbs.env" || exit 1
    SERVER_HOSTNAME=$PBS_SCHEDULER_HOSTNAME
fi

if [[ -n "$SERVER_HOSTNAME" ]]; then
    echo "$SERVER_HOSTNAME" > /var/spool/pbs/server_name
    chmod 0644 /var/spool/pbs/server_name || fail

    cp "${CYCLECLOUD_PROJECT_PATH}/default/templates/default/mom_config.template" /var/spool/pbs/mom_priv/config || fail
    chmod 0644 /var/spool/pbs/mom_priv/config || fail

    sed -e "s|__SERVERNAME__|$SERVER_HOSTNAME|g" \
        "${CYCLECLOUD_PROJECT_PATH}/default/templates/default/pbs.conf.template" > /etc/pbs.conf || fail
    chmod 0644 /etc/pbs.conf || fail
fi

# TODO: remove this chunk 
cp "${CYCLECLOUD_PROJECT_PATH}/default/templates/default/modify_limits.sh" /var/spool/pbs/modify_limits.sh || fail
chmod 0755 /var/spool/pbs/modify_limits.sh || fail

await_node_definition() {
    if ! /opt/pbs/bin/pbsnodes "$EXECUTE_HOSTNAME"; then
        echo "${EXECUTE_HOSTNAME} is not in the cluster yet. Retrying next converge" 1>&2
        return 1
    fi
}

MAX_RETRIES=10
RETRY_DELAY=15
ATTEMPT=1
if ! await_node_definition; then
    while [[ $ATTEMPT -lt $MAX_RETRIES ]]; do
        sleep $RETRY_DELAY
        ((ATTEMPT+=1))
        
        if await_node_definition; then
            break;
        fi
    done

    if [[ $ATTEMPT == $MAX_RETRIES ]]; then
        echo "Command failed after $MAX_RETRIES attempts. Exiting." 1>&2
        exit 1
    fi
fi

#This block will execute only if the "execute" node is defined in the PBS server
NODE_CREATED_GUARD="pbs.nodecreated" || fail
if [[ -f "$NODE_CREATED_GUARD" ]]; then
    echo "Node has already been created, skipping joining checks"
    exit 0
fi

NODE_ATTRS=$(/opt/pbs/bin/pbsnodes "$EXECUTE_HOSTNAME")
echo "$NODE_ATTRS" | grep -qi "$(jetpack config cyclecloud.node.id)"

if [[ $? -ne 0 ]]; then
    echo "Stale entry found for $EXECUTE_HOSTNAME. Waiting for autoscaler to update this before joining." 1>&2
    exit 1
fi

/opt/pbs/bin/pbsnodes -o "$EXECUTE_HOSTNAME" -C 'cyclecloud offline' && touch "$NODE_CREATED_GUARD" || fail